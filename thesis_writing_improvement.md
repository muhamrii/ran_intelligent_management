# Intelligent Network Management for Radio Access Networks Using Fine‚ÄëTuned Large Language Models and Knowledge Graph Retrieval

Author: <Your Name>
Supervisor: <Supervisor Name>
Institution: <Institution, Program>
Date: August 12, 2025

Note on title: The previously drafted title referenced a ‚ÄúMixture‚Äëof‚ÄëAgent Architecture,‚Äù however the final implementation integrates a fine‚Äëtuned intent model and a single LLM‚Äëassisted chatbot grounded by a Neo4j knowledge graph, without a multi‚Äëagent controller. The title is revised accordingly while preserving the core elements: Intelligent Network Management, RAN, fine‚Äëtuned LLM, and Knowledge Graph Retrieval.

---

## Abstract
Radio Access Networks (RAN) comprise thousands of interdependent parameters and tables, making day‚Äëto‚Äëday operations, triage, and performance analysis complex for engineers. This thesis proposes an intelligent network management system that unifies: (i) a parser that converts 3GPP Configuration Management (CM) XML into structured tables, (ii) a typed Neo4j knowledge graph of tables, columns, and discovered relationships, and (iii) a fine‚Äëtuned intent model with an LLM‚Äëassisted, domain‚Äëaware Natural Language Understanding (NLU) pipeline. The knowledge graph encodes semantic links discovered through name similarity, value overlap, RAN‚Äëpattern matches, and reference (key) relationships. The chatbot combines explicit table/column detection, semantic/domain retrieval, intent‚Äëguided ranking boosts, and structured response generation. The implementation provides a Streamlit research UI and an evaluation harness that separately measures Information Retrieval (IR) and NLU quality using curated ground truths. A phased NLU upgrade‚Äîenhanced responses, RAN‚Äëaware entity extraction, and multi‚Äëdimensional semantic similarity‚Äîimproves entity F1 and semantic alignment while preserving IR performance. This study follows Design Science Research Methodology (DSRM) to guide problem identification, artifact design, development, and evaluation. Results indicate robust IR accuracy for explicit queries and consistent NLU gains, suggesting that a schema‚Äëgrounded, fine‚Äëtuned LLM approach can increase explainability and operator trust in RAN management.

Keywords: Radio Access Networks (RAN), Knowledge Graph Retrieval, Fine‚ÄëTuned Large Language Models, Intent Detection, Intelligent Network Management, Semantic Similarity, Entity Extraction, Neo4j

---

## 1. Introduction

### 1.1 Background
Modern RAN deployments involve heterogeneous vendors and evolving standards (4G/5G/6G). Engineers must correlate configuration, counters, and alarms that are spread across many tables with opaque naming conventions. 3GPP CM XML typically enumerates network elements (e.g., eNodeB/gNodeB) and vendor‚Äëspecific `vsData*` objects that expand into tabular parameters. Columns may be nested, sparsely populated, or vendor‚Äëaliased, and entity relationships are implicit in names and values rather than explicitly declared foreign keys. Traditional tools (SQL/BI dashboards) require detailed schema knowledge and are brittle to naming idiosyncrasies and schema evolution.

LLMs can bridge user intent and data access, but they require strong grounding in structure and domain semantics to avoid hallucinations and off‚Äëtarget retrieval. A typed knowledge graph encodes structure and relationships, while a fine‚Äëtuned intent detector steers retrieval toward domain‚Äërelevant regions of the schema. A domain‚Äëaware NLU stack provides explicit entity extraction and multi‚Äësignal semantic similarity to stabilize answer quality across query types.

### 1.2 Research Problem
How can accurate, explainable, natural‚Äëlanguage access to RAN configuration and performance data be enabled, ensuring that LLM outputs are schema‚Äëaware and traceable, while providing reliable, reproducible evaluation of both retrieval and NLU quality? The solution must support explicit table/column queries, domain‚Äëoriented requests (e.g., power, performance, timing), and entity‚Äërich prompts, with consistent behavior under schema growth and vendor variance.

### 1.3 Objectives and Questions
Primary objective: Build and evaluate a system that parses RAN CM data, constructs a typed knowledge graph, and leverages a fine‚Äëtuned intent model with an LLM‚Äëassisted chatbot to answer queries with grounded, structured responses.

Secondary objectives: (a) isolate and preserve IR quality while iterating on NLU; (b) implement reproducible evaluation with curated ground truths; (c) provide explainable outputs with traceable entities and relationships.

Research questions:  
RQ1: What parsing and normalization are needed to convert 3GPP CM XML into a retrieval‚Äëfriendly graph?  
RQ2: How should a fine‚Äëtuned intent model be trained and integrated to guide graph retrieval?  
RQ3: Which domain‚Äëaware NLU components most improve answer quality without degrading IR performance?  
RQ4: How can IR and NLU be evaluated separately to support safe iteration?  
Success criteria: measurable NLU improvement (entity F1, semantic similarity) with no statistically significant IR regression on the curated benchmark set.

### 1.4 State of the Art (Summary)
Prior work spans LLMs, knowledge graphs, retrieval‚Äëaugmented generation (RAG), and network automation/SON. Many LLM‚Äëcentric systems perform text retrieval over documentation but lack fidelity to tabular schemas. Traditional dashboards and SQL tools provide precision but require schema expertise. Graph‚ÄëRAG integrates a knowledge graph but often omits explicit intent modeling tied to domain signals that can steer retrieval and explanations. A gap remains in schema‚Äëgrounded, explainable LLM answers that leverage a typed graph plus an intent model for domain alignment.

### 1.5 Gap Analysis
Gaps include: (1) limited typed relational structure under LLM answers; (2) weak domain grounding for steering retrieval; (3) scarce evaluation protocols that decouple IR from NLU; and (4) absence of an explicit intent model that informs ranking and explanation. This thesis addresses these by constructing a typed Neo4j graph, training an intent classifier, integrating domain‚Äëaware NLU components, and evaluating with decoupled IR/NLU metrics.

---

## 2. Literature Review

### 2.1 Radio Access Networks (RAN) ‚Äì evolution and challenges
RAN architectures have evolved from LTE to 5G NR with new spectrum, beamforming, and virtualization trends. Operational data grows in breadth (counters, KPIs) and heterogeneity (vendor‚Äëspecific parameters under `vsData*`). Configuration management relies on CM XML aligned to 3GPP Telecommunication Management (28‚Äëseries) but leaves practical mapping to operator tooling. These characteristics motivate a schema‚Äëaware, explainable interface for engineers.

References (selection):  
- J. G. Andrews et al., ‚ÄúWhat Will 5G Be?,‚Äù IEEE JSAC, 2014.  
- T. S. Rappaport et al., ‚ÄúMillimeter Wave Mobile Communications for 5G,‚Äù IEEE Access, 2013.  
- E. Dahlman, S. Parkvall, J. Sk√∂ld, 5G NR, Academic Press, 2018.  
- M. Shafi et al., ‚Äú5G: A Tutorial Overview of Standards, Trials, Challenges,‚Äù IEEE JSAC, 2017.  
- O‚ÄëRAN Alliance, White Papers, 2018‚Äì.  
- 3GPP TS 28.xxx series, Telecommunication management.

### 2.2 Fine‚ÄëTuned LLMs and Intent Classification
Transformer models support transfer learning for classification, including intent detection. Fine‚Äëtuning a pre‚Äëtrained encoder (e.g., BERT family) with domain‚Äëspecific utterances improves routing compared to keyword rules. Practical considerations include label taxonomy design, class imbalance, thresholding for confidence, and calibration to support fallbacks when uncertain.

References (selection):  
- A. Vaswani et al., NeurIPS, 2017.  
- J. Devlin et al., NAACL, 2019.  
- T. Brown et al., NeurIPS, 2020.  
- Y. Sun et al., CCL, 2019.  
- J. Howard, S. Ruder, ACL, 2018.  
- Hugging Face Transformers documentation.

### 2.3 Knowledge Graph Retrieval and Graph‚ÄëRAG
Knowledge graphs provide typed nodes and relationships that can constrain retrieval and improve explainability. Graph‚ÄëRAG augments generation with graph neighborhoods rather than text snippets alone. Neo4j is a practical backbone for schema‚Äëcentric applications due to Cypher, constraints, and tooling. Relationship discovery can combine embeddings, value overlap, pattern heuristics, and reference inference to enrich graph connectivity.

References (selection): Hamilton et al., 2017; Nickel et al., 2016; Ji et al., 2021; Lewis et al., 2020; Zhao et al., 2023; Neo4j docs.

### 2.4 Intelligent Network Management and SON
Intelligent network management spans configuration optimization, anomaly detection, and performance analysis. SON research emphasizes automation and policy‚Äëdriven adaptation. Integrating LLMs with operator data introduces new opportunities for intent‚Äëdriven workflows and explainable analytics when tightly coupled with structured representations like KGs.

References (selection): Aliu et al., 2013; Zhang et al., 2017; Musumeci et al., 2019; O‚ÄëRAN Alliance.

### 2.5 Related Works (comparative)
| Approach | Data | Retrieval | LLM/Model | Strengths | Limits |
|---|---|---|---|---|---|
| LLM‚Äëonly QA | Unstructured | Vector/keyword | Gen only | Easy to start | Weak schema fidelity |
| BI/SQL | RDB/CSV | SQL | None | Precise | Needs schema knowledge |
| Text‚ÄëRAG | Text | Vector | RAG | Good for docs | Weak on tabular semantics |
| Graph‚ÄëRAG | KG | Graph + vector | RAG | Structure‚Äëaware | Graph curation needed |
| This work | Typed Neo4j KG | Multi‚Äëstrategy + domain | Fine‚Äëtuned intent + LLM NLU | Schema‚Äëaware, traceable | Parser/KG ops required |

---

## 3. Methodology

### 3.1 Research Design (DSRM)
This study adopts DSRM: problem identification ‚Üí objectives ‚Üí design/development ‚Üí demonstration ‚Üí evaluation ‚Üí communication. The artifact is the end‚Äëto‚Äëend pipeline plus evaluation harness. Success is defined by reproducible builds, isolated IR benchmarks, and measurable NLU improvements without IR regressions.

### 3.2 System Architecture (code‚Äëaligned)
End‚Äëto‚Äëend modules and data flow:

1) Parser Module (`parser_module/parser.py`)  
‚Ä¢ Parses 3GPP CM XML and normalizes `vsData*` tags, including vendor‚Äëspecific expansions.  
‚Ä¢ Builds per‚Äëtable DataFrames; nested attributes are flattened with dot notation (`parent.child`).  
‚Ä¢ Outputs `(dfs, metadata, metadata2)`; `metadata2` lists parameter names per table to assist KG construction and UI surfacing.  
‚Ä¢ Error handling: tolerant to missing optional attributes; logs anomalies for operator review.

2) Knowledge Graph Module (`knowledge_graph_module/kg_builder.py`)  
‚Ä¢ Creates constraints for `Table(name)`, `Column(id)`, `Concept(name)` to enforce uniqueness and speed lookups.  
‚Ä¢ Materializes nodes for tables and columns; attaches column statistics (cardinality, sample values) for inspection.  
‚Ä¢ Discovers relationships with multiple detectors:  
  ‚Äì NAME_SIMILARITY via MiniLM‚ÄëL6‚Äëv2 embeddings and cosine similarity with thresholds.  
  ‚Äì VALUE_OVERLAP using Jaccard and overlap percentage on tokenized column values.  
  ‚Äì PATTERN_MATCH through RAN‚Äëspecific regex categories (IDs, time, status, measurement, frequency, power, config).  
  ‚Äì REFERENCES by subset checks hinting at FK‚ÜíPK correspondences.  
‚Ä¢ Serves schema overviews for UI and feeds retrieval with relationship‚Äëaware context.

3) Intent Model Fine‚ÄëTuning (new, code‚Äëaligned)  
Files: `chatbot_module/ran_training_data.json`, `chatbot_module/ran_finetuning.py`, `chatbot_module/ran_finetuning.ipynb`, `chatbot_module/ran_model_evaluation.ipynb`, artifacts in `chatbot_module/ran_domain_model/`.  
‚Ä¢ Labels: intents relevant to RAN operations (e.g., performance_analysis, power_optimization, spectrum_management, cell_configuration, quality_assessment, traffic_analysis, fault_detection, capacity_planning, interference_analysis, handover_optimization).  
‚Ä¢ Dataset: curated prompts and short utterances aligned with schema/domain terms; augmented with synonyms.  
‚Ä¢ Preprocessing: train/val split; tokenization via `AutoTokenizer`.  
‚Ä¢ Model: `AutoModelForSequenceClassification` (Transformer family).  
‚Ä¢ Training: cross‚Äëentropy loss; early stopping; class weighting if needed; typical hyperparams (lr ‚âà 2e‚Äë5, batch 16‚Äì32, epochs 3‚Äì8). Confidence calibration and thresholding are used to gate domain boosts at runtime.  
‚Ä¢ Evaluation: accuracy, macro‚ÄëF1, per‚Äëclass F1; confusion matrix analyzed for adjacent‚Äëintent confusions (e.g., performance vs capacity).  
‚Ä¢ Export: `config.json`, `tokenizer.json`, `model.safetensors`, `intent_labels.json` in `ran_domain_model/` for runtime use.  
‚Ä¢ Data governance: dataset versioned alongside code; label taxonomy documented for reproducibility.

4) Chatbot Module (`chatbot_module/chatbot.py`)  
‚Ä¢ Classes: `RANChatbot` (mixed with `EnhancedNLUMixin`) and `EnhancedRANChatbot`.  
‚Ä¢ Optional model loading: detects `ran_domain_model/` and loads tokenizer/model when present; otherwise applies keyword rules fallback.  
‚Ä¢ Optimized retrieval: explicit table extraction, semantic search, and domain boosts guided by predicted intent (`intent_domain_map`) and synonyms; caching (query/table/embedding/domain) with TTL and warm‚Äëup.  
‚Ä¢ Response generation: structured summaries of tables, columns, and relationships; formatting via `enhanced_nlu_functions.py`.  
‚Ä¢ KG context: includes related tables and relationship counts in ranking and explanation to improve transparency.

5) NLU Enhancements (`chatbot_module/enhanced_nlu_functions.py`)  
‚Ä¢ Phase 2: domain‚Äëaware response templates with structure markers (üìã/üîç/üìä/‚ö°/üì°/‚è±Ô∏è).  
‚Ä¢ Phase 3: entity extraction from query result + text (table/column regex, camelCase/PascalCase, RAN terminology + acronyms), normalization/deduplication, enhanced entity metrics.  
‚Ä¢ Phase 4: multi‚Äëdimensional semantic similarity (embedding + domain term overlap + structure + entity‚Äëmentions), safe fallbacks to token similarity for robustness.

6) Streamlit UI & Benchmarks (`chatbot_module/chatbot_ui.py`)  
‚Ä¢ Connection panel; auto‚Äëdiscovery of `ran_domain_model/`; cache metrics.  
‚Ä¢ Enhanced examples covering explicit, column‚Äëqualified, domain, and entity queries.  
‚Ä¢ Research Lab: separate IR and NLU benchmarks; visual metrics.

### 3.3 Intent Model ‚Üî Knowledge Graph Relationship
The intent detector informs retrieval by mapping predicted intents to domains (e.g., performance ‚Üí performance metrics, power ‚Üí energy/power tables). The chatbot applies:  
‚Ä¢ Domain boosts: intents bias ranking toward domain‚Äërelevant tables (via cached domain buckets).  
‚Ä¢ Relationship‚Äëaware context: KG relationships (NAME_SIMILARITY, REFERENCES, etc.) expand candidates and provide explanation fields (related tables, relationship types).  
‚Ä¢ Confidence gating: boosts are applied only when model confidence exceeds a threshold; otherwise the system defaults to neutral ranking.  
‚Ä¢ Safety: when the model is absent or uncertain, keyword rules and semantic search provide robust fallbacks.

Ranking formulation (conceptual):  
score(table) = Œ± ¬∑ semantic(table, query) + Œ≤ ¬∑ domain_boost(intent, table) + Œ≥ ¬∑ relationship_context(table), with Œ±, Œ≤, Œ≥ tuned to avoid IR regressions.

### 3.4 Implementation Notes
‚Ä¢ Regex for explicit tables supports uppercase, snake_case, and PascalCase; column patterns include camelCase/PascalCase.  
‚Ä¢ Caching warm‚Äëup loads all table names and builds domain buckets for fast boosts; cache keys include query text and normalized entities.  
‚Ä¢ The UI displays cache hit rate, cached tables, and extraction quality; provides quick ‚ÄúEnhanced Features‚Äù tests.  
‚Ä¢ Logging captures extraction steps, applied boosts, and selected relationships to aid explainability.  
‚Ä¢ Configuration is minimal and file‚Äëpath driven; absence of a fine‚Äëtuned model triggers automatic fallback.  
‚Ä¢ All NLU upgrades are isolated from IR logic to prevent regressions by design.

---

## 4. Evaluation Design

### 4.1 Datasets and Ground Truth
‚Ä¢ IR: `improved_ir_ground_truth.csv` with input queries and expected tables/columns, used to compute retrieval precision/recall/F1.  
‚Ä¢ NLU: `enhanced_nlu_ground_truth.csv` (100 entries; query/answer/entities) for semantic similarity and entity extraction metrics.  
‚Ä¢ Intent: `ran_training_data.json` for fine‚Äëtuning; model artifacts in `ran_domain_model/` for runtime inference.

### 4.2 Metrics
‚Ä¢ IR: precision/recall/F1 for tables and columns; mean reciprocal rank (MRR) as an optional rank metric.  
‚Ä¢ NLU: multi‚Äëdimensional semantic similarity; entity precision/recall/F1; structured‚Äëresponse rate; answer latency.  
‚Ä¢ Intent: accuracy, macro‚ÄëF1, per‚Äëclass F1, confusion matrix; confidence calibration quality (ECE) if available.

### 4.3 Protocol
‚Ä¢ Baseline: IR pipeline with keyword intent rules enabled and no fine‚Äëtuned model loaded.  
‚Ä¢ Intent Ablation: enable the fine‚Äëtuned model; measure retrieval and end‚Äëto‚Äëend answer impact versus baseline.  
‚Ä¢ NLU Phases: P1 (ground truth fix), P2 (responses), P3 (entities), P4 (similarity); measure deltas with IR held constant via isolated retrieval logic.  
‚Ä¢ Robustness: validate that fallbacks preserve answer quality when the model is missing or low‚Äëconfidence; confirm that confidence gating prevents adverse boosts.  
‚Ä¢ Reproducibility: fix random seeds for data splits; version datasets and model artifacts together with the codebase.

---

## 5. Results

Summary aligned to the current implementation and validations:
‚Ä¢ IR: Near‚Äëperfect explicit table retrieval on the curated set; competitive domain/entity retrieval aided by relationship‚Äëaware boosts; no regressions observed during NLU upgrades due to retrieval isolation.  
‚Ä¢ Intent: The fine‚Äëtuned model increases routing accuracy relative to keyword rules; improves ranking alignment and response focus. Confusions primarily occur among closely related intents (e.g., performance vs capacity), which is mitigated by confidence gating.  
‚Ä¢ NLU: Structured responses increase answer consistency; RAN‚Äëaware extraction improves entity F1; multi‚Äëdimensional similarity stabilizes semantic alignment across query forms. Caching reduces median latency and supports interactive use.

Ablation notes:  
‚Ä¢ P2 (responses) yields immediate gains in structured‚Äëresponse rate and perceived clarity.  
‚Ä¢ P3 (entities) raises entity precision/recall and enhances explainability via explicit entity lists.  
‚Ä¢ P4 (similarity) reduces variance in semantic alignment, especially for domain‚Äëheavy queries.  
‚Ä¢ Enabling the intent model provides measurable ranking gains on domain queries without harming explicit retrieval.

---

## 6. Discussion

### 6.1 Contributions
‚Ä¢ A practical, code‚Äëcomplete pipeline from 3GPP parsing to a typed Neo4j graph to a fine‚Äëtuned, intent‚Äëaware chatbot.  
‚Ä¢ A multi‚Äësignal KG relationship discovery pipeline tailored to RAN data.  
‚Ä¢ A phase‚Äëbased NLU enhancement stack and a decoupled IR/NLU benchmark harness.  
‚Ä¢ Integration of a fine‚Äëtuned intent model with domain boosts over a KG for explainable improvements.

### 6.2 Practical Impact
‚Ä¢ Faster, explainable schema exploration; grounded, structured answers; operator‚Äëfriendly interaction.  
‚Ä¢ Intent‚Äëguided ranking improves relevance for performance, power, frequency, timing, and configuration tasks.  
‚Ä¢ Caching supports responsive UX as graph size and table counts grow.

### 6.3 Risks and Mitigations
‚Ä¢ Hallucinations ‚Üí Grounding in KG; explicit table/column mentions; conservative templates with structured sections.  
‚Ä¢ Model drift ‚Üí Versioned ground truths and datasets; periodic re‚Äëtraining; keyword fallbacks; confidence thresholds.  
‚Ä¢ Graph staleness ‚Üí Scheduled re‚Äëingestion and relationship refresh; change detection and alerting; provenance metadata.

### 6.4 Future Work
‚Ä¢ Enrich ontology and counters; concept hierarchies; provenance across hops.  
‚Ä¢ Graph and cross‚Äëencoder rerankers for retrieval; uncertainty estimates and confidence bands in responses.  
‚Ä¢ Larger public‚Äëlike datasets for broader generalization; online learning from operator feedback.

---

## 7. Conclusion
This thesis presents an intelligent, schema‚Äëgrounded RAN management system unifying a fine‚Äëtuned intent model, a Neo4j knowledge graph, and an LLM‚Äëassisted NLU stack. The approach keeps IR strong while improving NLU quality, producing explainable answers with traceable entities and relationships. The codebase includes reproducible parsing, KG construction, model training/evaluation, and a Streamlit research UI, enabling future extensions in both retrieval and generation. The separation of IR and NLU evaluation enables safe iteration and supports continued research on domain‚Äëaware LLM systems for telecom operations.

---

## 8. References (IEEE style)
[1] J. G. Andrews et al., IEEE JSAC, 2014.  
[2] T. S. Rappaport et al., IEEE Access, 2013.  
[3] E. Dahlman et al., 5G NR, Academic Press, 2018.  
[4] M. Shafi et al., IEEE JSAC, 2017.  
[5] O‚ÄëRAN Alliance, White Papers.  
[6] 3GPP TS 28.xxx, Telecommunication management.  
[7] A. Vaswani et al., NeurIPS, 2017.  
[8] J. Devlin et al., NAACL, 2019.  
[9] T. B. Brown et al., NeurIPS, 2020.  
[10] Y. Sun et al., CCL, 2019.  
[11] J. Howard, S. Ruder, ACL, 2018.  
[12] W. Hamilton et al., 2017.  
[13] M. Nickel et al., Proc. IEEE, 2016.  
[14] S. Ji et al., IEEE TKDE, 2021.  
[15] P. Lewis et al., NeurIPS, 2020.  
[16] S. Zhao et al., 2023.  
[17] C. Sun et al., ACL, 2019.  
[18] M. Aliu et al., IEEE Comm. Surveys & Tutorials, 2013.  
[19] H. Zhang et al., IEEE Comm. Mag., 2017.  
[20] Neo4j product documentation.

---

## Appendices

### A. Code Artifacts and Paths (for replication)
‚Ä¢ Parser: `parser_module/parser.py`  
‚Ä¢ Knowledge Graph: `knowledge_graph_module/kg_builder.py`  
‚Ä¢ Intent training: `chatbot_module/ran_finetuning.py`, `ran_finetuning.ipynb`, data `ran_training_data.json`  
‚Ä¢ Model artifacts: `chatbot_module/ran_domain_model/` (config, tokenizer, weights, labels)  
‚Ä¢ Chatbot: `chatbot_module/chatbot.py` (loads model if available; keyword fallback)  
‚Ä¢ NLU: `chatbot_module/enhanced_nlu_functions.py`  
‚Ä¢ UI/Benchmarks: `chatbot_module/chatbot_ui.py`  
‚Ä¢ Ground truths: `improved_ir_ground_truth.csv`, `enhanced_nlu_ground_truth.csv`

### B. Suggested Figures
‚Ä¢ End‚Äëto‚Äëend architecture (Parser ‚Üí KG ‚Üí Intent Model ‚Üí Chatbot ‚Üí UI)  
‚Ä¢ KG relationship types and examples  
‚Ä¢ Intent model training/evaluation pipeline  
‚Ä¢ IR vs NLU benchmark separation and metrics

### C. Environment and Reproducibility Notes
‚Ä¢ Python: see `requirements.txt`; ensure compatible versions for Transformers, SentenceTransformers, Neo4j driver, Streamlit.  
‚Ä¢ Data paths: paths are file‚Äëbased; the chatbot auto‚Äëdetects `ran_domain_model/` if present.  
‚Ä¢ Reproducibility: datasets and model artifacts are versioned with the repository; random seeds fixed in fine‚Äëtuning scripts/notebooks.  
‚Ä¢ Privacy: training data should avoid sensitive operator information; use synthetic or anonymized prompts when necessary.
